{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Day 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Function to find the 10 most frequent words\n",
    "def most_frequent_words(text, top_n=10):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    word_counter = Counter(words)\n",
    "    most_common = word_counter.most_common(top_n)\n",
    "    \n",
    "    return most_common\n",
    "\n",
    "# URL for Romeo and Juliet text\n",
    "romeo_and_juliet_url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "# Get text from the URL\n",
    "romeo_and_juliet_text = get_text_from_url(romeo_and_juliet_url)\n",
    "\n",
    "# Find the 10 most frequent words\n",
    "most_common_words = most_frequent_words(romeo_and_juliet_text, top_n=10)\n",
    "\n",
    "# Print the result\n",
    "print(\"10 Most Frequent Words:\")\n",
    "for word, count in most_common_words:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Cat Weights (in metric units):\n",
      "min: 2.00\n",
      "max: 5.00\n",
      "mean: 3.22\n",
      "median: 3.00\n",
      "std_dev: 0.88\n",
      "\n",
      "Statistics for Cat Lifespans (in years):\n",
      "min: 10.50\n",
      "max: 19.00\n",
      "mean: 13.75\n",
      "median: 13.50\n",
      "std_dev: 1.58\n",
      "\n",
      "Frequency Table of Country and Breed:\n",
      "Egypt - Abyssinian: 1 times\n",
      "Greece - Aegean: 1 times\n",
      "United States - American Bobtail: 1 times\n",
      "United States - American Curl: 1 times\n",
      "United States - American Shorthair: 1 times\n",
      "United States - American Wirehair: 1 times\n",
      "United Arab Emirates - Arabian Mau: 1 times\n",
      "Australia - Australian Mist: 1 times\n",
      "United States - Balinese: 1 times\n",
      "United States - Bambino: 1 times\n",
      "United States - Bengal: 1 times\n",
      "France - Birman: 1 times\n",
      "United States - Bombay: 1 times\n",
      "United Kingdom - British Longhair: 1 times\n",
      "United Kingdom - British Shorthair: 1 times\n",
      "Burma - Burmese: 1 times\n",
      "United Kingdom - Burmilla: 1 times\n",
      "United States - California Spangled: 1 times\n",
      "United States - Chantilly-Tiffany: 1 times\n",
      "France - Chartreux: 1 times\n",
      "Egypt - Chausie: 1 times\n",
      "United States - Cheetoh: 1 times\n",
      "United States - Colorpoint Shorthair: 1 times\n",
      "United Kingdom - Cornish Rex: 1 times\n",
      "Canada - Cymric: 1 times\n",
      "Cyprus - Cyprus: 1 times\n",
      "United Kingdom - Devon Rex: 1 times\n",
      "Russia - Donskoy: 1 times\n",
      "China - Dragon Li: 1 times\n",
      "Egypt - Egyptian Mau: 1 times\n",
      "Burma - European Burmese: 1 times\n",
      "United States - Exotic Shorthair: 1 times\n",
      "United Kingdom - Havana Brown: 1 times\n",
      "United States - Himalayan: 1 times\n",
      "Japan - Japanese Bobtail: 1 times\n",
      "United States - Javanese: 1 times\n",
      "Thailand - Khao Manee: 1 times\n",
      "Thailand - Korat: 1 times\n",
      "Russia - Kurilian: 1 times\n",
      "Thailand - LaPerm: 1 times\n",
      "United States - Maine Coon: 1 times\n",
      "United Kingdom - Malayan: 1 times\n",
      "Isle of Man - Manx: 1 times\n",
      "United States - Munchkin: 1 times\n",
      "United States - Nebelung: 1 times\n",
      "Norway - Norwegian Forest Cat: 1 times\n",
      "United States - Ocicat: 1 times\n",
      "United States - Oriental: 1 times\n",
      "Iran (Persia) - Persian: 1 times\n",
      "United States - Pixie-bob: 1 times\n",
      "United States - Ragamuffin: 1 times\n",
      "United States - Ragdoll: 1 times\n",
      "Russia - Russian Blue: 1 times\n",
      "United States - Savannah: 1 times\n",
      "United Kingdom - Scottish Fold: 1 times\n",
      "United States - Selkirk Rex: 1 times\n",
      "Thailand - Siamese: 1 times\n",
      "Russia - Siberian: 1 times\n",
      "Singapore - Singapura: 1 times\n",
      "United States - Snowshoe: 1 times\n",
      "Somalia - Somali: 1 times\n",
      "Canada - Sphynx: 1 times\n",
      "Canada - Tonkinese: 1 times\n",
      "United States - Toyger: 1 times\n",
      "Turkey - Turkish Angora: 1 times\n",
      "Turkey - Turkish Van: 1 times\n",
      "United States - York Chocolate: 1 times\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from statistics import mean, median, stdev\n",
    "from collections import Counter\n",
    "\n",
    "def get_cats_data(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    cats_data = response.json()\n",
    "    return cats_data\n",
    "\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "cats_data = get_cats_data(cats_api)\n",
    "\n",
    "weights = []\n",
    "lifespans = []\n",
    "country_breed_freq = Counter()\n",
    "\n",
    "for cat in cats_data:\n",
    "    if 'weight' in cat:\n",
    "        weight_metric = cat['weight']['metric']\n",
    "        weight_value = float(weight_metric.split()[0])  \n",
    "        weights.append(weight_value)\n",
    "\n",
    "    if 'life_span' in cat:\n",
    "        lifespan_years = cat['life_span']\n",
    "        if '-' in lifespan_years:\n",
    "            lifespan_values = [float(value) for value in lifespan_years.split('-')]\n",
    "            lifespan_years = mean(lifespan_values)\n",
    "        else:\n",
    "            lifespan_years = float(lifespan_years)\n",
    "        lifespans.append(lifespan_years)\n",
    "\n",
    "    \n",
    "    if 'origin' in cat and 'name' in cat:\n",
    "        country_breed_freq[(cat['origin'], cat['name'])] += 1\n",
    "\n",
    "\n",
    "weight_stats = {\n",
    "    'min': min(weights),\n",
    "    'max': max(weights),\n",
    "    'mean': mean(weights),\n",
    "    'median': median(weights),\n",
    "    'std_dev': stdev(weights)\n",
    "}\n",
    "\n",
    "lifespan_stats = {\n",
    "    'min': min(lifespans),\n",
    "    'max': max(lifespans),\n",
    "    'mean': mean(lifespans),\n",
    "    'median': median(lifespans),\n",
    "    'std_dev': stdev(lifespans)\n",
    "}\n",
    "\n",
    "print(\"Statistics for Cat Weights (in metric units):\")\n",
    "for stat, value in weight_stats.items():\n",
    "    print(f\"{stat}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nStatistics for Cat Lifespans (in years):\")\n",
    "for stat, value in lifespan_stats.items():\n",
    "    print(f\"{stat}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nFrequency Table of Country and Breed:\")\n",
    "for (country, breed), freq in country_breed_freq.items():\n",
    "    print(f\"{country} - {breed}: {freq} times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Largest Countries:\n",
      "Rank Country                                  Total Area (sq km)\n",
      "============================================================\n",
      "1   Russian Federation                       17124442.0     \n",
      "2   Antarctica                               14000000.0     \n",
      "3   Canada                                   9984670.0      \n",
      "4   China                                    9640011.0      \n",
      "5   United States of America                 9629091.0      \n",
      "6   Brazil                                   8515767.0      \n",
      "7   Australia                                7692024.0      \n",
      "8   India                                    3287590.0      \n",
      "9   Argentina                                2780400.0      \n",
      "10  Kazakhstan                               2724900.0      \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "\n",
    "\n",
    "response = requests.get(countries_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Sort countries based on total area in descending order\n",
    "    sorted_countries = sorted(countries_data, key=lambda x: x.get('area', 0), reverse=True)\n",
    "\n",
    "    # Get the top 10 largest countries\n",
    "    top_10_largest_countries = sorted_countries[:10]\n",
    "\n",
    "    # Print the list of 10 largest countries\n",
    "    print(\"Top 10 Largest Countries:\")\n",
    "    print(\"{:<3} {:<40} {:<15}\".format(\"Rank\", \"Country\", \"Total Area (sq km)\"))\n",
    "    print(\"=\"*60)\n",
    "    for i, country in enumerate(top_10_largest_countries, start=1):\n",
    "        country_name = country.get('name', '')\n",
    "        total_area = country.get('area', 0)\n",
    "        print(\"{:<3} {:<40} {:<15}\".format(i, country_name, total_area))\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the countries API. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Spoken Languages:\n",
      "Rank Language                  Frequency \n",
      "==================================================\n",
      "1   English                   91        \n",
      "2   French                    45        \n",
      "3   Arabic                    25        \n",
      "4   Spanish                   24        \n",
      "5   Portuguese                10        \n",
      "6   Russian                   8         \n",
      "7   Dutch                     8         \n",
      "8   German                    7         \n",
      "9   Chinese                   5         \n",
      "10  Serbian                   4         \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the countries API\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(countries_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Extract language names from all countries\n",
    "    all_languages = [language['name'] for country in countries_data for language in country.get('languages', [])]\n",
    "\n",
    "    # Create a frequency table for languages\n",
    "    language_frequency = {}\n",
    "    for language in all_languages:\n",
    "        language_frequency[language] = language_frequency.get(language, 0) + 1\n",
    "\n",
    "    # Sort languages based on frequency in descending order\n",
    "    sorted_languages = sorted(language_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 10 most spoken languages\n",
    "    top_10_languages = sorted_languages[:10]\n",
    "\n",
    "    # Print the list of 10 most spoken languages\n",
    "    print(\"Top 10 Most Spoken Languages:\")\n",
    "    print(\"{:<3} {:<25} {:<10}\".format(\"Rank\", \"Language\", \"Frequency\"))\n",
    "    print(\"=\"*50)\n",
    "    for i, (language, frequency) in enumerate(top_10_languages, start=1):\n",
    "        print(\"{:<3} {:<25} {:<10}\".format(i, language, frequency))\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the countries API. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of languages in the countries API: 112\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the countries API\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(countries_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Extract language codes from all countries\n",
    "    all_languages = [language.get('iso639_1', None) for country in countries_data for language in country.get('languages', [])]\n",
    "\n",
    "    # Remove None values\n",
    "    all_languages = [lang for lang in all_languages if lang is not None]\n",
    "\n",
    "    # Get the total number of unique languages\n",
    "    total_languages = len(set(all_languages))\n",
    "\n",
    "    print(f\"Total number of languages in the countries API: {total_languages}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the countries API. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the page. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the UCI Machine Learning Repository\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find and print the content of the page (you can customize this based on your needs)\n",
    "    content = soup.prettify()  # You can use soup.text for plain text without indentation\n",
    "    print(content)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
